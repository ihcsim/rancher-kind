# Create Harvester Guest Cluster Via Rancher API

This example demonstrates how to generate a Harvester guest cluster specification containing a basic node pool. It assumes the kustomize configurations are stored at the `base` root folder with the following layout:
```sh
✗ tree base
base
├── cluster.yaml
├── kustomization.yaml
├── patches
│   ├── cluster.yaml
│   └── nodepool.yaml
└── secrets
    └── kubeconfig.yaml
```

Export the following variables in the current shell:
```sh
export CLUSTER_NAME=<cluster_name>

# can be obtained from rancher ui
export CLOUD_CREDENTIAL_SECRET_NAME="cattle-global-data:cc-<secret-name-suffix>"
export RKE2_VERSION="<rke2-version>"

# can be obtained from harvester ui
export VM_IMAGE_NAME=<vm_image_name>
export VM_NETWORK_NAME=<vm_network_name>
export VM_NAMESPACE=<vm_namespace>
```

Clone the `cluster-template-examples` repository:
```sh
git clone https://github.com/rancher/cluster-template-examples.git
```

Generate the base `Cluster` and `HarvesterConfig` YAML and save it to `./base/cluster.yaml`:
```sh
helm template -n fleet-default \
  --set cluster.name="${CLUSTER_NAME}" \
  --set cloudCredentialSecretName="${CLOUD_CREDENTIAL_SECRET_NAME}" \
  --set kubernetesVersion="${RKE2_VERSION}" \
  -f ./cluster-template-examples/charts/values-harvester.yaml \
  harvester ./cluster-template-examples/charts > ./base/cluster.yaml
```

On the Harvester node, generate the kubeconfig credentials needed by the Harvester cloud provider and save it to `./base/secrets/kubeconfig.yaml`:
```sh
curl -sfL https://raw.githubusercontent.com/harvester/cloud-provider-harvester/master/deploy/generate_addon.sh | bash -s default ${CLUSTER_NAME} | sed -n '/# cloud config #/,/# cloud-init user data #/{//!p}' > ./base/secrets/kubeconfig.yaml
```

Save the following kustomize configuration to `./base/kustomization.yaml`:
```sh
cat <<EOF > ./base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: fleet-default
resources:
- cluster.yaml
patches:
- path: patches/nodepool.yaml
  target:
    group: rke-machine-config.cattle.io
    version: v1
    kind: HarvesterConfig
    name: harvester-nodepool-1
- path: patches/cluster.yaml
  target:
    group: provisioning.cattle.io
    version: v1
    kind: Cluster
    name: "${CLUSTER_NAME}"
secretGenerator:
- name: harvesterconfig-"${CLUSTER_NAME"}
  type: secret
  files: 
  - credential=secrets/kubeconfig.yaml
  options:
    annotations:
      v2prov-authorized-secret-deletes-on-cluster-removal: "true"
      v2prov-secret-authorized-for-cluster: "${CLUSTER_NAME}"
generatorOptions:
 disableNameSuffixHash: true
EOF
```

Save the following cluster patch to `./base/patches/cluster.yaml`:
```sh
cat <<EOF > ./base/patches/cluster.yaml
apiVersion: provisioning.cattle.io/v1
kind: Cluster
metadata:
  name: "${CLUSTER_NAME}"
  namespace: fleet-default
spec:
  rkeConfig:
    chartValues:
      harvester-cloud-provider:
        cloudConfigPath: /var/lib/rancher/rke2/etc/config-files/cloud-provider-config
        global:
          cattle:
            clusterName: "${CLUSTER_NAME}"
      rke2-calico: {}
    machineGlobalConfig:
      cni: calico
    machineSelectorConfig:
    - config:
        cloud-provider-config: secret://fleet-default:harvesterconfig-${CLUSTER_NAME}
        cloud-provider-name: harvester
        protect-kernel-defaults: false
EOF
```

Save the following nodepool patch to `./base/patches/nodepool.yaml`:
```sh
cat <<EOF > ./base/patches/nodepool.yaml
apiVersion: rke-machine-config.cattle.io/v1
kind: HarvesterConfig
metadata:
  name: harvester-nodepool-1
  namespace: fleet-default
cpuCount: "2"
diskInfo: '{"disks":[{"imageName":"${VM_NAMESPACE}/${VM_IMAGE_NAME}","bootOrder":1,"size":40}]}'
enableEfi: false
enableSecureBoot: false
memorySize: "4"
networkInfo: '{"interfaces":[{"networkName":"${VM_NAMESPACE}/${VM_NETWORK_NAME}","macAddress":""}]}'
sshPort: "22"
sshUser: ubuntu
userData: I2Nsb3VkLWNvbmZpZwpwYWNrYWdlX3VwZGF0ZTogdHJ1ZQpwYWNrYWdlczoKICAtIHFlbXUtZ3Vlc3QtYWdlbnQKcnVuY21kOgogIC0gLSBzeXN0ZW1jdGwKICAgIC0gZW5hYmxlCiAgICAtICctLW5vdycKICAgIC0gcWVtdS1ndWVzdC1hZ2VudC5zZXJ2aWNlCg==
vmNamespace: "${VM_NAMESPACE}"
EOF
```

Validate the final output generated by kustomize before applying:
```sh
kubectl kustomize ./base
```

When everything correct, apply the cluster configuration:
```sh
kubectl kustomize ./base | kubectl apply -f -
```
